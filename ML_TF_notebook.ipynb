{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff69d918",
   "metadata": {},
   "source": [
    "# End-to-End TensorFlow Pipeline Notebook\n",
    "\n",
    "Dieses Notebook f√ºhrt dich Schritt f√ºr Schritt durch einen kompletten Machine-Learning-Workflow mit TensorFlow:\n",
    "\n",
    "1. **Daten-Pipeline**: Laden, Vorverarbeiten und Batchen von Bildern mit `tf.data`.\n",
    "2. **TFRecord-Erstellung**: Konvertiere deine Bilder und Labels in das effiziente TFRecord-Format.\n",
    "3. **Basic CNN**: Implementiere ein einfaches Convolutional Neural Network (CNN) von Grund auf.\n",
    "4. **Pretrained ResNet**: Nutze ein ResNet-Modell mit vortrainierten Gewichten.\n",
    "5. **Modellspeicherung**: Speichere und lade dein trainiertes Modell.\n",
    "6. **Evaluation**: Beurteile die Modellleistung auf einem Evaluierungsdatensatz.\n",
    "\n",
    "Jede Zelle enth√§lt ausf√ºhrliche Erkl√§rungen und Verweise auf die TensorFlow-Dokumentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d6af7",
   "metadata": {},
   "source": [
    "## 1. Setup und Imports\n",
    "\n",
    "Wir starten mit den ben√∂tigten Bibliotheken. Stelle sicher, dass TensorFlow 2.x installiert ist.\n",
    "\n",
    "Referenzen:\n",
    "- TensorFlow Installationsanleitung: https://www.tensorflow.org/install\n",
    "- TensorFlow 2 Guide: https://www.tensorflow.org/guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3805b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7aaa337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andi ist cool\n"
     ]
    }
   ],
   "source": [
    "print(\"Andi ist cool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63ca3a",
   "metadata": {},
   "source": [
    "## 2. Daten-Pipeline erstellen\n",
    "\n",
    "Wir erstellen zwei separate Datens√§tze:\n",
    "- **Trainings-Datensatz**: Zum Trainieren unseres Modells\n",
    "- **Evaluierungs-Datensatz**: Zum Testen unseres Modells\n",
    "\n",
    "Die Pipeline l√§dt Bilder aus Ordnern, verkleinert sie auf eine einheitliche Gr√∂√üe und normalisiert die Pixelwerte.\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Bilder werden geladen und in das richtige Format gebracht\n",
    "- Pixelwerte werden von 0-255 auf 0-1 normalisiert (das hilft beim Training)\n",
    "- Bilder werden in kleinere Gruppen (Batches) aufgeteilt\n",
    "\n",
    "**Wichtig:** Wir verwenden hier bewusst einfache Schleifen ohne parallele Verarbeitung, damit der Code leichter zu verstehen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c124029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATEN-PIPELINE: TRAININGS- UND EVALUIERUNGS-DATENS√ÑTZE ERSTELLEN\n",
    "# =============================================================================\n",
    "\n",
    "# Pfade zu den beiden Datensatz-Ordnern\n",
    "train_data_dir = Path(\"./data/uni_test_train_ds\")\n",
    "eval_data_dir = Path(\"./data/uni_test_eval_ds\")\n",
    "\n",
    "# Parameter f√ºr die Bildverarbeitung\n",
    "batch_size = 4           # Anzahl Bilder pro Batch\n",
    "img_size = (256, 256)    # Alle Bilder werden auf diese Gr√∂√üe verkleinert\n",
    "\n",
    "# =============================================================================\n",
    "# HILFSFUNKTIONEN\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_process_image(image_path):\n",
    "    \"\"\"\n",
    "    L√§dt ein PNG-Bild und bereitet es f√ºr das Training vor.\n",
    "    \"\"\"\n",
    "    # Bild von Festplatte lesen und dekodieren\n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image_raw, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # Auf einheitliche Gr√∂√üe verkleinern und normalisieren\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = image / 255.0  # Werte von 0-255 auf 0-1 bringen\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_labels_from_json(labels_file):\n",
    "    \"\"\"\n",
    "    L√§dt die Labels aus einer Label Studio JSON-Datei.\n",
    "    \"\"\"\n",
    "    with open(labels_file, 'r') as f:\n",
    "        label_data = json.load(f)\n",
    "    \n",
    "    # Dictionary zum Zuordnen von Bildnamen zu Labels\n",
    "    image_to_label = {}\n",
    "    \n",
    "    for item in label_data:\n",
    "        # Bildpfad extrahieren\n",
    "        image_path = item['data']['image']\n",
    "        filename = image_path.split('/')[-1]  # Nur Dateiname\n",
    "        \n",
    "        # Label extrahieren\n",
    "        if item['annotations'] and len(item['annotations']) > 0:\n",
    "            annotation = item['annotations'][0]\n",
    "            if annotation['result'] and len(annotation['result']) > 0:\n",
    "                label = annotation['result'][0]['value']['choices'][0]\n",
    "                image_to_label[filename] = label\n",
    "    \n",
    "    return image_to_label\n",
    "\n",
    "def create_dataset_from_directory(data_dir):\n",
    "    \"\"\"\n",
    "    Erstellt einen TensorFlow-Datensatz aus PNG-Bildern und Label Studio Labels.\n",
    "    \"\"\"\n",
    "    print(f\"Erstelle Datensatz aus: {data_dir}\")\n",
    "    \n",
    "    # Labels aus JSON-Datei laden\n",
    "    labels_file = data_dir / \"labels\" / f\"labels_{data_dir.name}.json\"\n",
    "    image_to_label = load_labels_from_json(labels_file)\n",
    "    print(f\"Labels geladen: {len(image_to_label)} Eintr√§ge\")\n",
    "    \n",
    "    # Alle PNG-Bilder finden (der Ordner hei√üt 'images', nicht 'imgs')\n",
    "    image_dir = data_dir / \"images\"\n",
    "    image_paths = list(image_dir.glob(\"*.png\"))\n",
    "    print(f\"Gefundene PNG-Bilder: {len(image_paths)}\")\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(f\"WARNUNG: Keine PNG-Bilder in {image_dir} gefunden!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Listen f√ºr Bilder und Labels erstellen\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Jedes Bild verarbeiten\n",
    "    for image_path in image_paths:\n",
    "        filename = image_path.name\n",
    "        \n",
    "        # Pr√ºfen ob Label vorhanden ist\n",
    "        if filename in image_to_label:\n",
    "            # Bild laden\n",
    "            image = load_and_process_image(str(image_path))\n",
    "            images.append(image)\n",
    "            \n",
    "            # Label hinzuf√ºgen\n",
    "            label = image_to_label[filename]\n",
    "            labels.append(label)\n",
    "    \n",
    "    print(f\"Bilder mit Labels verarbeitet: {len(images)}\")\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"FEHLER: Keine Bilder mit passenden Labels gefunden!\")\n",
    "        return None, None\n",
    "    \n",
    "    # In TensorFlow-Tensoren umwandeln\n",
    "    images_tensor = tf.stack(images)\n",
    "    \n",
    "    # Klassen sortieren und in Zahlen umwandeln\n",
    "    unique_classes = sorted(list(set(labels)))\n",
    "    print(f\"Klassen: {unique_classes}\")\n",
    "    \n",
    "    label_to_index = {name: i for i, name in enumerate(unique_classes)}\n",
    "    numeric_labels = [label_to_index[label] for label in labels]\n",
    "    labels_tensor = tf.constant(numeric_labels)\n",
    "    \n",
    "    # TensorFlow-Dataset erstellen und batchen\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images_tensor, labels_tensor))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset, unique_classes\n",
    "\n",
    "# =============================================================================\n",
    "# DATENS√ÑTZE ERSTELLEN\n",
    "# =============================================================================\n",
    "\n",
    "# Trainings-Datensatz\n",
    "print(\"üîÑ Erstelle Trainings-Datensatz...\")\n",
    "train_dataset, train_classes = create_dataset_from_directory(train_data_dir)\n",
    "\n",
    "# Evaluierungs-Datensatz\n",
    "print(\"\\nüîÑ Erstelle Evaluierungs-Dataset...\")\n",
    "eval_dataset, eval_classes = create_dataset_from_directory(eval_data_dir)\n",
    "\n",
    "# Klassennamen f√ºr sp√§ter speichern und einmal zusammenfassen\n",
    "class_names = train_classes if train_classes else []\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Zusammenfassung der erstellten Datasets\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìä DATASET-√úBERSICHT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"‚úÖ Trainings-Dataset: {len(train_classes) if train_classes else 0} Klassen\")\n",
    "print(f\"‚úÖ Evaluierungs-Dataset: {len(eval_classes) if eval_classes else 0} Klassen\")\n",
    "print(f\"üè∑Ô∏è  Erkannte Klassen: {class_names}\")\n",
    "print(f\"üî¢ Anzahl Klassen: {num_classes}\")\n",
    "\n",
    "# Pr√ºfen ob beide Datasets die gleichen Klassen haben\n",
    "if train_classes and eval_classes:\n",
    "    if set(train_classes) == set(eval_classes):\n",
    "        print(\"‚úÖ Beide Datasets haben identische Klassen - perfekt!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNUNG: Verschiedene Klassen in Train/Eval Datasets!\")\n",
    "        print(f\"   Train: {train_classes}\")\n",
    "        print(f\"   Eval:  {eval_classes}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f027eb",
   "metadata": {},
   "source": [
    "## 3. TFRecord-Datensatz erstellen\n",
    "\n",
    "Wir speichern die vorverarbeiteten Bilder und Labels im TFRecord-Format.\n",
    "\n",
    "- **`tf.train.Example`**: Struktur f√ºr einzelne Instanzen\n",
    "- **`tf.io.TFRecordWriter`**: Schreibt bin√§re Dateien\n",
    "\n",
    "Referenz:\n",
    "- TFRecord Guide: https://www.tensorflow.org/tutorials/load_data/tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TFRECORD-DATENS√ÑTZE ERSTELLEN\n",
    "# =============================================================================\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Hilfsfunktion f√ºr Bytes-Features.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Hilfsfunktion f√ºr Integer-Features.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_tfrecord(dataset, output_file, dataset_name):\n",
    "    \"\"\"\n",
    "    Erstellt eine TFRecord-Datei aus einem Dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Erstelle {dataset_name} TFRecord: {output_file}\")\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_file) as writer:\n",
    "        for images, labels in dataset:\n",
    "            for img, lbl in zip(images, labels):\n",
    "                # Bild als PNG kodieren (besser f√ºr PNGs als JPEG)\n",
    "                img_raw = tf.io.encode_png(tf.cast(img * 255, tf.uint8)).numpy()\n",
    "                \n",
    "                # Feature erstellen\n",
    "                feature = {\n",
    "                    'image_raw': _bytes_feature(img_raw),\n",
    "                    'label': _int64_feature(int(lbl.numpy()))\n",
    "                }\n",
    "                \n",
    "                # Example erstellen und schreiben\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example.SerializeToString())\n",
    "    \n",
    "    print(f\"{dataset_name} TFRecord erstellt!\")\n",
    "\n",
    "# TFRecord-Dateien erstellen\n",
    "train_record_file = './data/train_dataset.tfrecord'\n",
    "eval_record_file = './data/eval_dataset.tfrecord'\n",
    "\n",
    "if train_dataset is not None:\n",
    "    create_tfrecord(train_dataset, train_record_file, \"Trainings\")\n",
    "\n",
    "if eval_dataset is not None:\n",
    "    create_tfrecord(eval_dataset, eval_record_file, \"Evaluierungs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10fe601",
   "metadata": {},
   "source": [
    "## 4. TFRecord-Dataset laden\n",
    "\n",
    "Wir laden den TFRecord-Datensatz und wandeln die `Example`-Protobufs zur√ºck in Tensors um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TFRECORD-DATASETS LADEN UND F√úR TRAINING VORBEREITEN\n",
    "# =============================================================================\n",
    "\n",
    "def parse_tfrecord_example(example_proto):\n",
    "    \"\"\"\n",
    "    Wandelt ein TFRecord-Example zur√ºck in Bild und Label um.\n",
    "    \"\"\"\n",
    "    # Schema definieren\n",
    "    feature_description = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    # Example parsen\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Bild dekodieren (PNG, da wir PNG kodiert haben)\n",
    "    image = tf.io.decode_png(parsed['image_raw'], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, img_size) / 255.0\n",
    "    \n",
    "    # Label in One-Hot-Encoding umwandeln\n",
    "    label = tf.one_hot(parsed['label'], depth=num_classes)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def load_and_split_tfrecord_dataset(record_file, dataset_name, train_split=0.8):\n",
    "    \"\"\"\n",
    "    L√§dt ein TFRecord-Dataset und teilt es in Training und Validation auf.\n",
    "    \"\"\"\n",
    "    print(f\"Lade {dataset_name} TFRecord: {record_file}\")\n",
    "    \n",
    "    # TFRecord-Dataset laden\n",
    "    raw_dataset = tf.data.TFRecordDataset(record_file)\n",
    "    \n",
    "    # Examples parsen\n",
    "    parsed_dataset = raw_dataset.map(parse_tfrecord_example)\n",
    "    \n",
    "    # Dataset-Gr√∂√üe ermitteln (ungef√§hr)\n",
    "    dataset_size = sum(1 for _ in parsed_dataset)\n",
    "    print(f\"Dataset-Gr√∂√üe: {dataset_size} Beispiele\")\n",
    "    \n",
    "    # Dataset shuffeln f√ºr bessere Aufteilung\n",
    "    shuffled_dataset = parsed_dataset.shuffle(buffer_size=dataset_size, seed=42)\n",
    "    \n",
    "    # Train/Validation Split\n",
    "    train_size = int(dataset_size * train_split)\n",
    "    val_size = dataset_size - train_size\n",
    "    \n",
    "    train_dataset = shuffled_dataset.take(train_size)\n",
    "    val_dataset = shuffled_dataset.skip(train_size)\n",
    "    \n",
    "    # Batchen\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    \n",
    "    print(f\"Training: {train_size} Beispiele ({train_split*100:.0f}%)\")\n",
    "    print(f\"Validation: {val_size} Beispiele ({(1-train_split)*100:.0f}%)\")\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def load_tfrecord_dataset(record_file, dataset_name):\n",
    "    \"\"\"\n",
    "    L√§dt ein TFRecord-Dataset f√ºr Evaluation (ohne Split).\n",
    "    \"\"\"\n",
    "    print(f\"Lade {dataset_name} TFRecord: {record_file}\")\n",
    "    \n",
    "    # TFRecord-Dataset laden\n",
    "    raw_dataset = tf.data.TFRecordDataset(record_file)\n",
    "    \n",
    "    # Examples parsen\n",
    "    parsed_dataset = raw_dataset.map(parse_tfrecord_example)\n",
    "    \n",
    "    # Batchen\n",
    "    batched_dataset = parsed_dataset.batch(batch_size)\n",
    "    \n",
    "    return batched_dataset\n",
    "\n",
    "# =============================================================================\n",
    "# DATASETS LADEN UND AUFTEILEN\n",
    "# =============================================================================\n",
    "\n",
    "# Trainings-TFRecord laden und in Train/Validation aufteilen\n",
    "train_tfrecord_dataset = None\n",
    "val_tfrecord_dataset = None\n",
    "eval_tfrecord_dataset = None\n",
    "\n",
    "if os.path.exists(train_record_file):\n",
    "    print(\"üìä Lade und teile Trainings-Dataset auf...\")\n",
    "    train_tfrecord_dataset, val_tfrecord_dataset = load_and_split_tfrecord_dataset(\n",
    "        train_record_file, \"Trainings\", train_split=0.8\n",
    "    )\n",
    "\n",
    "# Evaluierungs-TFRecord separat laden (wird nicht zum Training verwendet)\n",
    "if os.path.exists(eval_record_file):\n",
    "    print(\"\\nüìä Lade Evaluierungs-Dataset...\")\n",
    "    eval_tfrecord_dataset = load_tfrecord_dataset(eval_record_file, \"Evaluierungs\")\n",
    "\n",
    "# Zusammenfassung der verf√ºgbaren Datasets\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìä VERF√úGBARE DATASETS F√úR TRAINING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"‚úÖ Training-Dataset: {train_tfrecord_dataset}\")\n",
    "print(f\"‚úÖ Validation-Dataset: {val_tfrecord_dataset}\")\n",
    "print(f\"üìã Evaluation-Dataset: {eval_tfrecord_dataset} (nur f√ºr finale Evaluation)\")\n",
    "print(f\"üî¢ Anzahl Klassen: {num_classes}\")\n",
    "print(f\"üè∑Ô∏è  Klassennamen: {class_names}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ff924",
   "metadata": {},
   "source": [
    "## 5. Basic CNN erstellen und trainieren\n",
    "\n",
    "Ein einfaches CNN zum Einstieg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BASIC CNN ERSTELLEN UND TRAINIEREN\n",
    "# =============================================================================\n",
    "\n",
    "# Einfaches CNN-Modell erstellen\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(*img_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Basic CNN Modell-Architektur:\")\n",
    "model.summary()\n",
    "\n",
    "# Training mit Train/Validation Split (80/20)\n",
    "epochs = 5\n",
    "\n",
    "if train_tfrecord_dataset is not None and val_tfrecord_dataset is not None:\n",
    "    print(f\"\\nüöÄ Trainiere Basic CNN f√ºr {epochs} Epochen...\")\n",
    "    print(\"üìä Training: 80% der Daten\")\n",
    "    print(\"üìä Validation: 20% der Daten\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_tfrecord_dataset,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_tfrecord_dataset,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Training abgeschlossen!\")\n",
    "else:\n",
    "    print(\"‚ùå Kein Trainings-Dataset verf√ºgbar. √úberspringe Training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a67b0b",
   "metadata": {},
   "source": [
    "## 6. Pretrained ResNet nutzen\n",
    "\n",
    "Wir verwenden `tf.keras.applications.ResNet50` mit vortrainierten ImageNet-Gewichten.\n",
    "\n",
    "Referenz:\n",
    "- Keras Applications: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PRETRAINED RESNET NUTZEN\n",
    "# =============================================================================\n",
    "\n",
    "# ResNet50 Basis-Modell laden (ohne Top-Layer)\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(*img_size, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Basis-Modell einfrieren (Transfer Learning)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Eigenes Top-Layer hinzuf√ºgen\n",
    "inputs = tf.keras.Input(shape=(*img_size, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "resnet_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "resnet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"ResNet50 Transfer Learning Modell-Architektur:\")\n",
    "resnet_model.summary()\n",
    "\n",
    "# Training mit Train/Validation Split (80/20)\n",
    "if train_tfrecord_dataset is not None and val_tfrecord_dataset is not None:\n",
    "    print(f\"\\nüöÄ Trainiere ResNet50 f√ºr 3 Epochen...\")\n",
    "    print(\"üìä Training: 80% der Daten\")\n",
    "    print(\"üìä Validation: 20% der Daten\")\n",
    "    \n",
    "    resnet_history = resnet_model.fit(\n",
    "        train_tfrecord_dataset,\n",
    "        epochs=3,\n",
    "        validation_data=val_tfrecord_dataset,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ ResNet Training abgeschlossen!\")\n",
    "else:\n",
    "    print(\"‚ùå Kein Trainings-Dataset verf√ºgbar. √úberspringe Training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66f42f",
   "metadata": {},
   "source": [
    "## 7. Modell speichern und laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODELL SPEICHERN UND LADEN\n",
    "# =============================================================================\n",
    "\n",
    "# Ordner f√ºr gespeicherte Modelle erstellen\n",
    "os.makedirs('./saved_models', exist_ok=True)\n",
    "\n",
    "# Basic CNN Modell speichern\n",
    "cnn_model_path = './saved_models/basic_cnn.keras'\n",
    "model.save(cnn_model_path)\n",
    "print(f\"Basic CNN Modell gespeichert unter: {cnn_model_path}\")\n",
    "\n",
    "# ResNet Modell speichern (falls trainiert)\n",
    "if 'resnet_model' in locals():\n",
    "    resnet_model_path = './saved_models/resnet_model.keras'\n",
    "    resnet_model.save(resnet_model_path)\n",
    "    print(f\"ResNet Modell gespeichert unter: {resnet_model_path}\")\n",
    "\n",
    "# Modell wieder laden (Beispiel)\n",
    "print(\"\\nLade gespeichertes Modell...\")\n",
    "loaded_model = tf.keras.models.load_model(cnn_model_path)\n",
    "print(\"Modell erfolgreich geladen!\")\n",
    "\n",
    "# Kurze √úbersicht des geladenen Modells\n",
    "print(\"\\n√úbersicht des geladenen Modells:\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd3156",
   "metadata": {},
   "source": [
    "## 8. Ausf√ºhrliche Modell-Evaluation\n",
    "\n",
    "Wir evaluieren beide Modelle (Basic CNN und ResNet) ausf√ºhrlich mit verschiedenen TensorFlow-Metriken:\n",
    "\n",
    "- **Accuracy**: Wie oft liegt das Modell richtig?\n",
    "- **Loss**: Wie sicher ist sich das Modell bei seinen Vorhersagen?\n",
    "- **Confusion Matrix**: Welche Klassen werden verwechselt?\n",
    "- **Classification Report**: Detaillierte Metriken pro Klasse\n",
    "\n",
    "Referenzen:\n",
    "- TensorFlow Metrics: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "- Model Evaluation: https://www.tensorflow.org/guide/keras/evaluate_and_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ada48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODELL-EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(model, dataset, model_name):\n",
    "    \"\"\"Einfache und √ºbersichtliche Modell-Evaluation.\"\"\"\n",
    "    if dataset is None:\n",
    "        print(f\"‚ùå {model_name}: Kein Dataset verf√ºgbar\")\n",
    "        return None\n",
    "    \n",
    "    # Standard TensorFlow Evaluation\n",
    "    loss, accuracy = model.evaluate(dataset, verbose=0)\n",
    "    \n",
    "    # Vorhersagen sammeln f√ºr detaillierte Analyse\n",
    "    predictions = model.predict(dataset, verbose=0)\n",
    "    y_pred = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Wahre Labels sammeln\n",
    "    y_true = []\n",
    "    for _, labels in dataset:\n",
    "        y_true.extend(tf.argmax(labels, axis=1).numpy())\n",
    "    \n",
    "    return {\n",
    "        'name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'loss': loss,\n",
    "        'predictions': y_pred.numpy(),\n",
    "        'true_labels': y_true\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION DURCHF√úHREN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üîç Modell-Evaluation\\n\")\n",
    "\n",
    "# Beide Modelle evaluieren\n",
    "cnn_results = evaluate_model(model, eval_tfrecord_dataset, \"Basic CNN\")\n",
    "resnet_results = evaluate_model(resnet_model, eval_tfrecord_dataset, \"ResNet50\")\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "results = [cnn_results, resnet_results]\n",
    "results = [r for r in results if r is not None]  # Nur verf√ºgbare Ergebnisse\n",
    "\n",
    "if results:\n",
    "    print(f\"{'Modell':<15} {'Accuracy':<12} {'Loss':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for result in results:\n",
    "        acc = f\"{result['accuracy']:.3f}\"\n",
    "        loss = f\"{result['loss']:.3f}\"\n",
    "        print(f\"{result['name']:<15} {acc:<12} {loss:<10}\")\n",
    "    \n",
    "    # Bestes Modell ermitteln\n",
    "    best_model = max(results, key=lambda x: x['accuracy'])\n",
    "    print(f\"\\nüèÜ Bestes Modell: {best_model['name']} ({best_model['accuracy']:.1%} Accuracy)\")\n",
    "    \n",
    "    # Klassenweise Accuracy (exemplarisch)\n",
    "    print(f\"\\nüìä Klassenverteilung (Evaluations-Dataset):\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        count = sum(1 for label in best_model['true_labels'] if label == i)\n",
    "        print(f\"   {class_name}: {count} Samples\")\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab2f4e",
   "metadata": {},
   "source": [
    "## 9. Fazit und Ausblick\n",
    "\n",
    "### Was du gelernt hast:\n",
    "\n",
    "1. **Daten-Pipeline**: Effizientes Laden und Vorverarbeiten von Bilddaten mit Label Studio JSON-Labels\n",
    "2. **TFRecord-Format**: Optimierte Datenspeicherung f√ºr gro√üe Datasets\n",
    "3. **CNN von Grund auf**: Aufbau eines einfachen Convolutional Neural Networks\n",
    "4. **Transfer Learning**: Nutzung vortrainierter ResNet50-Gewichte\n",
    "5. **Modellspeicherung**: Persistierung trainierter Modelle\n",
    "6. **Umfassende Evaluation**: Professionelle Bewertung mit TensorFlow-Metriken\n",
    "\n",
    "### Wichtige Erkenntnisse:\n",
    "\n",
    "- **TFRecord** erm√∂glicht effizientes Streaming gro√üer Datasets\n",
    "- **Transfer Learning** kann deutlich bessere Ergebnisse erzielen als Training von Grund auf\n",
    "- **Evaluation** sollte immer mehrere Metriken und Visualisierungen umfassen\n",
    "- **Einfacher Code** ist oft besser als komplizierte Parallelverarbeitung (f√ºr Lernzwecke)\n",
    "\n",
    "### N√§chste Schritte:\n",
    "\n",
    "- **Data Augmentation**: Erweitere den Datensatz k√ºnstlich\n",
    "- **Hyperparameter Tuning**: Optimiere Lernrate, Batch-Gr√∂√üe, etc.\n",
    "- **Andere Architekturen**: Probiere EfficientNet, Vision Transformer\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Weiterf√ºhrende Ressourcen:\n",
    "\n",
    "**TensorFlow Grundlagen:**\n",
    "- [TensorFlow Guide](https://www.tensorflow.org/guide)\n",
    "- [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "\n",
    "**Daten-Pipeline:**\n",
    "- [tf.data Guide](https://www.tensorflow.org/guide/data)\n",
    "- [TFRecord Tutorial](https://www.tensorflow.org/tutorials/load_data/tfrecord)\n",
    "\n",
    "**Computer Vision:**\n",
    "- [Image Classification Tutorial](https://www.tensorflow.org/tutorials/images/classification)\n",
    "- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
    "\n",
    "**Evaluation & Metriken:**\n",
    "- [Model Evaluation](https://www.tensorflow.org/guide/keras/evaluate_and_predict)\n",
    "- [TensorFlow Metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n",
    "\n",
    "**Production Deployment:**\n",
    "- [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)\n",
    "- [TensorFlow Lite](https://www.tensorflow.org/lite)\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Tipps f√ºr eigene Projekte:\n",
    "\n",
    "1. **Starte einfach**: Verwende erst kleine Datasets und einfache Modelle\n",
    "2. **Visualisiere alles**: Confusion Matrix, Trainingsverl√§ufe, Datenverteilung\n",
    "3. **Dokumentiere**: Notiere Hyperparameter und Ergebnisse\n",
    "4. **Validiere richtig**: Trenne Training, Validation und Evaluierung strikt\n",
    "5. **Iteriere**: Verbessere schrittweise statt alles auf einmal zu √§ndern"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
