{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff69d918",
   "metadata": {},
   "source": [
    "# End-to-End TensorFlow Pipeline Notebook\n",
    "\n",
    "Dieses Notebook führt dich Schritt für Schritt durch einen kompletten Machine-Learning-Workflow mit TensorFlow:\n",
    "\n",
    "1. **Daten-Pipeline**: Laden, Vorverarbeiten und Batchen von Bildern mit `tf.data`.\n",
    "2. **TFRecord-Erstellung**: Konvertiere deine Bilder und Labels in das effiziente TFRecord-Format.\n",
    "3. **Basic CNN**: Implementiere ein einfaches Convolutional Neural Network (CNN) von Grund auf.\n",
    "4. **Pretrained ResNet**: Nutze ein ResNet-Modell mit vortrainierten Gewichten.\n",
    "5. **Modellspeicherung**: Speichere und lade dein trainiertes Modell.\n",
    "6. **Evaluation**: Beurteile die Modellleistung auf einem Evaluierungsdatensatz.\n",
    "\n",
    "Jede Zelle enthält ausführliche Erklärungen und Verweise auf die TensorFlow-Dokumentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d6af7",
   "metadata": {},
   "source": [
    "## 1. Setup und Imports\n",
    "\n",
    "Wir starten mit den benötigten Bibliotheken. Stelle sicher, dass TensorFlow 2.x installiert ist.\n",
    "\n",
    "Referenzen:\n",
    "- TensorFlow Installationsanleitung: https://www.tensorflow.org/install\n",
    "- TensorFlow 2 Guide: https://www.tensorflow.org/guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3805b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63ca3a",
   "metadata": {},
   "source": [
    "## 2. Daten-Pipeline mit `tf.data`\n",
    "\n",
    "Wir erstellen eine Pipeline, die Bilder aus einem Verzeichnis lädt, skaliert und in Batches organisiert.\n",
    "\n",
    "- **`tf.data.Dataset.list_files`**: Findet Bilddateien\n",
    "- **`tf.data.Dataset.map`**: Wendet Vorverarbeitung an\n",
    "- **`tf.data.Dataset.batch`** und **`prefetch`**: Effizientes Batch-Training\n",
    "\n",
    "Referenz:\n",
    "- `tf.data` API: https://www.tensorflow.org/guide/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c124029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu deinem Bild-Ordner (Unterordner je Klasse)\n",
    "data_dir = Path(\"./images\")\n",
    "\n",
    "# Parameter\n",
    "auto = tf.data.AUTOTUNE\n",
    "batch_size = 4\n",
    "img_size = (256, 256)\n",
    "\n",
    "# Funktion zur Verarbeitung jedes Bildes und Labels\n",
    "def process_path(file_path):\n",
    "    label = tf.strings.split(file_path, os.path.sep)[-2]\n",
    "    label = tf.cast(label == class_names, tf.int32)\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = image / 255.0  # Normalisierung\n",
    "    return image, label\n",
    "\n",
    "# Klassen extrahieren\n",
    "class_names = np.array(sorted([d.name for d in data_dir.iterdir() if d.is_dir()]))\n",
    "\n",
    "# Dataset erstellen\n",
    "autotune = tf.data.AUTOTUNE\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir / \"*\" / \"*.png\"), shuffle=True)\n",
    "processed_ds = list_ds.map(process_path, num_parallel_calls=autotune)\n",
    "dataset = processed_ds.batch(batch_size).prefetch(autotune)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f027eb",
   "metadata": {},
   "source": [
    "## 3. TFRecord-Datensatz erstellen\n",
    "\n",
    "Wir speichern die vorverarbeiteten Bilder und Labels im TFRecord-Format.\n",
    "\n",
    "- **`tf.train.Example`**: Struktur für einzelne Instanzen\n",
    "- **`tf.io.TFRecordWriter`**: Schreibt binäre Dateien\n",
    "\n",
    "Referenz:\n",
    "- TFRecord Guide: https://www.tensorflow.org/tutorials/load_data/tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Helfer\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# Pfad für TFRecord-File\n",
    "record_file = './data/dataset.tfrecord'\n",
    "\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for images, labels in dataset:\n",
    "        for img, lbl in zip(images, labels):\n",
    "            img_raw = tf.io.encode_jpeg(tf.cast(img*255, tf.uint8)).numpy()\n",
    "            feature = {\n",
    "                'image_raw': _bytes_feature(img_raw),\n",
    "                'label': _int64_feature(int(lbl.numpy().argmax()))\n",
    "            }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "print(f\"TFRecord erstellt: {record_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10fe601",
   "metadata": {},
   "source": [
    "## 4. TFRecord-Dataset laden\n",
    "\n",
    "Wir laden den TFRecord-Datensatz und wandeln die `Example`-Protobufs zurück in Tensors um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(record_file)\n",
    "\n",
    "# Schema definieren\n",
    "def parse_example(example_proto):\n",
    "    feature_description = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.io.decode_jpeg(parsed['image_raw'], channels=3)\n",
    "    image = tf.image.resize(image, img_size) / 255.0\n",
    "    label = tf.one_hot(parsed['label'], depth=len(class_names))\n",
    "    return image, label\n",
    "\n",
    "parsed_ds = raw_dataset.map(parse_example, num_parallel_calls=autotune)\n",
    "dataset = parsed_ds.batch(batch_size).prefetch(autotune)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ff924",
   "metadata": {},
   "source": [
    "## 5. Basic CNN erstellen und trainieren\n",
    "\n",
    "Ein einfaches CNN zum Einstieg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(*img_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "epochs = 10\n",
    "history = model.fit(dataset, epochs=epochs, validation_data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a67b0b",
   "metadata": {},
   "source": [
    "## 6. Pretrained ResNet nutzen\n",
    "\n",
    "Wir verwenden `tf.keras.applications.ResNet50` mit vortrainierten ImageNet-Gewichten.\n",
    "\n",
    "Referenz:\n",
    "- Keras Applications: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(*img_size, 3), include_top=False, weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False  # Gefrieren der Basisschichten\n",
    "\n",
    "inputs = tf.keras.Input(shape=(*img_size, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)\n",
    "resnet_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "resnet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_model.summary()\n",
    "\n",
    "# Feinabstimmung (optional)\n",
    "resnet_model.fit(dataset, epochs=5, validation_data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66f42f",
   "metadata": {},
   "source": [
    "## 7. Modell speichern und laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern\n",
    "model_path = './saved_models/basic_cnn'\n",
    "tf.keras.models.save_model(model, model_path)\n",
    "print(f\"Modell gespeichert unter: {model_path}\")\n",
    "\n",
    "# Laden\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "loaded_model.summary()\n",
    "result = loaded_model.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd3156",
   "metadata": {},
   "source": [
    "## 8. Evaluation auf Evaluierungsdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ada48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angenommen, eval_dataset ist schon definiert\n",
    "results = loaded_model.evaluate(dataset)\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846465f",
   "metadata": {},
   "source": [
    "## Fazit und Ausblick\n",
    "\n",
    "- Du hast gelernt, wie man eine komplette Pipeline mit TensorFlow erstellt.\n",
    "- TFRecord ermöglicht effizientes Daten-Streaming.\n",
    "- Keras-API eignet sich für schnelle Prototypen und komplexe Modelle.\n",
    "- **Ausblick**: Transfer Learning vertiefen, TensorFlow Lite für mobile Geräte, TensorFlow Serving für produktive Systeme.\n",
    "\n",
    "---\n",
    "\n",
    "# Referenzen\n",
    "\n",
    "- https://www.tensorflow.org/guide/data\n",
    "- https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "- https://www.tensorflow.org/guide/keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
